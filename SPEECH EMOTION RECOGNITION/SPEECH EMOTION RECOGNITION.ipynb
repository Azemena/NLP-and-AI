{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPEECH EMOTION RECOGNITION ( SER )\n",
    "\n",
    "Contexte:\n",
    "Reconnaissance des émotions vocales des clients à partir de la parole, dans les centres d'appels, afin d'améliorer le service.\n",
    "\n",
    "SER = reconnaître les émotions humaines et les états affectifs de la parole, ( en effet, la voix reflète souvent l'émotion sous-jacente à travers le ton et la hauteur. C'est également le phénomène que les animaux comme les chiens et les chevaux utilisent pour comprendre les émotions humaines). \n",
    "\n",
    "SER est difficile car les émotions sont subjectives et l'annotation audio est difficile.\n",
    "\n",
    "LIBROSA =  bibliothèque Python pour analyser l'audio et la musique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconnaissance des émotions de la parole:\n",
    "Objectif:Construire un modèle pour reconnaître l'émotion de la parole en utilisant les bibliothèques LIBROSA, SKLEARN et le jeu de données RAVDESS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconnaissance des émotions vocales \n",
    "nous utiliserons les bibliothèques LIBROSA, SOUNDFILE et SKLEARN (entre autres) pour construire un modèle à l'aide d'un MLPClassifier. Cela sera capable de reconnaître l'émotion des fichiers sonores.\n",
    "1- Nous allons charger les données, \n",
    "2- en extraire les caractéristiques,\n",
    "3- puis diviser l'ensemble de données en ensembles d'entraînement et de test. \n",
    "4- Ensuite, nous initialiserons un MLPClassifier et formerons le modèle. \n",
    "5- Enfin, nous calculerons la précision de notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'ensemble de données\n",
    "Pour ce mini projet Python, nous utiliserons le jeu de données RAVDESS; il s'agit de l'ensemble de données Ryerson Audio-Visual Database of Emotional Speech and Song. \n",
    "\n",
    "Cet ensemble de données contient 7356 fichiers évalués par 247 personnes 10 fois sur la validité émotionnelle, l'intensité et l'authenticité. \n",
    "\n",
    "L'ensemble de données est de 24,8 Go provenant de 24 acteurs, mais nous avons réduit le taux d'échantillonnage sur tous les fichiers, et vous pouvez le téléchargeable ici: https://drive.google.com/file/d/1wWsrN2Ep7x6lWqOXfr4rpKGYrJhWc8z7/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Installation des bibliothèques LIBROSA, NUMPY, SKLEARN, PYAUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - librosa\n",
      "  - sklearn\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install librosa numpy sklearn pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- Importation des packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3- Définissons les fonctions:\n",
    " \n",
    "1- extract_feature = pour extraire les fonctionnalités mfcc, chroma et mel d'un fichier son. Cette fonction prend   4 paramètres (le nom du fichier et trois paramètres booléens pour les trois fonctionnalités). \n",
    "\n",
    "mfcc = Mel Frequency Cepstral Coefficient, représente le spectre de puissance à court terme d'un son\n",
    "chroma = concerne les 12 classes de hauteur différentes\n",
    "mel =  Fréquence du spectrogramme Mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- DataFlair - Extrait des fonctionnalités (mfcc, chroma, mel) d'un fichier son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-  Maintenant, définissons un dictionnaire pour contenir les nombres et les émotions disponibles dans le jeu \n",
    "#   de données RAVDESS, et une liste pour contenir ceux que nous voulons - calmes, heureux, craintifs, dégoûtants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFlair - Émotions dans le jeu de données RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFlair - Émotions à observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Maintenant, chargeons les données avec une fonction load_data () qui prend en paramètre la taille relative de l'ensemble de test. x et y sont des listes vides; nous utiliserons la fonction glob () du module glob pour obtenir tous les chemins d'accès aux fichiers audio de notre jeu de données. \n",
    "\n",
    "Donc, pour chacun de ces chemins, obtenons le nom de base du fichier, l'émotion en divisant le nom autour de '-' et en extrayant la troisième valeur:\n",
    "\n",
    "En utilisant notre dictionnaire d'émotions, ce nombre est transformé en émotion, et notre fonction vérifie si cette émotion est dans notre liste d'émotions observées; sinon, il passe au fichier suivant. Il fait un appel à extract_feature et stocke ce qui est retourné dans 'feature'. Ensuite, il ajoute la fonctionnalité à x et l'émotion à y. Ainsi, la liste x contient les caractéristiques et y contient les émotions. Nous appelons la fonction train_test_split avec ceux-ci, la taille du test et une valeur d'état aléatoire, et la retournons a ala fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6- DataFlair - Chargement des données et extraction des fonctionnalités pour chaque fichier son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"/home/le/Documents/Python_Env/SPEECH EMOTION RECOGNITION/DataFlair/Actor_*/*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7- Il est temps de diviser l'ensemble de données en ensembles de formation et de test! Gardons \n",
    "#  l'ensemble de test à 25% de tout et utilisons la fonction load_data pour cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DataFlair - Diviser le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8- Observation de la forme des ensembles de données d'entraînement et de test:\n",
    "# DataFlair - Obtention de la forme des ensembles de données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 192)\n"
     ]
    }
   ],
   "source": [
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8- obtenons le nombre d'entités extraites.\n",
    "# DataFlair - Obtenez le nombre de fonctionnalités extraites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9- Maintenant, initialisons un MLPClassifier. Il s'agit d'un classificateur Perceptron multicouche; il optimise la fonction de perte logarithmique en utilisant LBFGS ou la descente de gradient stochastique. Contrairement à SVM ou Naive Bayes , le MLPClassifier dispose d'un réseau neuronal interne à des fins de classification. Il s'agit d'un modèle ANN anticipé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFlair - Initialiser le classificateur Perceptron multicouche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustons et entraînez le modèle.\n",
    "# #DataFlair - Formation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédisons les valeurs de l'ensemble de test. Cela nous donne y_pred (les émotions prédites pour les\n",
    "# fonctionnalités de l'ensemble de test).\n",
    "\n",
    "# DataFlair - Prédire pour l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer la précision de notre modèle, nous allons appeler la fonction precision_score () que nous avons importée de sklearn . Enfin, nous arrondirons la précision à 2 décimales et l'afficherons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Calculez la précision de notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFlair - Imprimer la précision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.88%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résumé\n",
    "Dans ce mini projet Python, nous avons appris à reconnaître les émotions de la parole. \n",
    "Nous avons utilisé un MLPClassifier pour cela et avons utilisé la bibliothèque de fichiers sonores pour lire le fichier audio et la bibliothèque librosa pour en extraire des fonctionnalités.\n",
    "\n",
    "Comme nous le voyons, le modèle a fourni une précision de 71,88%. C'est encore assez bon pour nous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
