{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETECTING FAKKE  NEWS WITH PYTHON\n",
    "\n",
    "L'objectif de ce projet est d'apprendre comment faire facilement la différence entre les vraies et les fausses nouvelles sur les réseaux sociaux.\n",
    "\n",
    "Quelques thematiques\n",
    "\n",
    "TF ( Term Frequency )= Nombre de fois qu'un mot apparait dans un document.\n",
    "Une valeur plus élevée signifie qu'un terme apparaît plus souvent que d'autres, et donc, le document est une bonne correspondance lorsque le terme fait partie des termes de recherche.\n",
    "\n",
    "IDF ( INVERSE dOCUMENT fREQUENCY ):\n",
    "Les mots qui apparaissent plusieurs fois dans un document, mais qui apparaissent également plusieurs fois dans de nombreux autres, peuvent ne pas être pertinents. La FID est une mesure de l'importance d'un terme dans l'ensemble du corpus.\n",
    "\n",
    "Le TfidfVectorizer convertit une collection de documents bruts en une matrice de fonctionnalités TF-IDF.\n",
    "\n",
    "Le PassiveAgressiveClassifier, est un algorithme d'apprentissage en ligne, son but est de faire des mise a jour qui corrigent la perte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'ensemble de données\n",
    "\n",
    "L'ensemble de données a une forme de 7796 × 4. La première colonne identifie les nouvelles, les deuxième et troisième sont le titre et le texte, et la quatrième colonne a des étiquettes indiquant si les nouvelles sont RÉELLES ou FAUX. L'ensemble de données occupe 29,2 Mo d'espace et vous pouvez le télécharger ici . https://drive.google.com/file/d/1er9NJTLUA3qnRuyhfzuN0XUsoIC4a-_q/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Installation des bibliothèques \n",
    "# NUMPY\n",
    "# PANDAS \n",
    "# SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/le/anaconda3/lib/python3.8/site-packages (1.18.5)\n",
      "Requirement already satisfied: pandas in /home/le/anaconda3/lib/python3.8/site-packages (1.0.5)\n",
      "Requirement already satisfied: sklearn in /home/le/anaconda3/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/le/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/le/anaconda3/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: scikit-learn in /home/le/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/le/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/le/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/le/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/le/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- Effectuons les importations nécessaires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-Lecture des données dans un DataFrame et obtention des données et des 5 premiers enregistrements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data\n",
    "df=pd.read_csv('/home/le/Documents/Python_Env/DETECTING FAKE NEWS WITH PYTHON/news.csv')\n",
    "#Get shape and head\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- Récupération des étiquettes du DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    FAKE\n",
       "1    FAKE\n",
       "2    REAL\n",
       "3    FAKE\n",
       "4    REAL\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFlair - Get the labels\n",
    "labels=df.label\n",
    "labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5- Divisons l'ensemble de données en ensembles d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Split the dataset\n",
    "x_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Initialisation d'un TfidfVectorizer avec des mots vides de la langue anglaise et une fréquence de document maximale de 0,7 (les termes avec une fréquence de document plus élevée seront supprimés). Les mots vides sont les mots les plus courants dans une langue qui doivent être filtrés avant de traiter les données en langage naturel. Et un TfidfVectorizer transforme une collection de documents bruts en une matrice de fonctionnalités TF-IDF.\n",
    "\n",
    "Maintenant, ajustons et transformons le vectoriseur sur l'ensemble de train, et transformez le vectoriseur sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Initialize a TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "#DataFlair - Fit and transform train set, transform test set\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(x_train) \n",
    "tfidf_test=tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- Initialiserons ensuite un PassiveAggressiveClassifier.\n",
    "\n",
    "Nous allons adapter ceci sur tfidf_train et y_train.\n",
    "\n",
    "Ensuite, nous allons prédire sur l'ensemble de test du TfidfVectorizer et calculer la précision avec precision_score () à partir de sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.9%\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Initialize a PassiveAggressiveClassifier\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train,y_train)\n",
    "#DataFlair - Predict on the test set and calculate accuracy\n",
    "y_pred=pac.predict(tfidf_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8- Nous avons obtenu une précision de 92,82% avec ce modèle. Enfin, imprimons une matrice de confusion pour avoir un aperçu du nombre de faux et vrais négatifs et positifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[589,  49],\n",
       "       [ 41, 588]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFlair - Build confusion matrix\n",
    "confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donc, avec ce modèle, nous avons 589 vrais positifs, 587 vrais négatifs, 42 faux positifs et 49 faux négatifs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résumé\n",
    "\n",
    "Par ce travail, nous avons appris à détecter les fausses nouvelles avec Python. Pour cella, \n",
    "\n",
    "1- nous avons pris un ensemble de données politiques, \n",
    "\n",
    "2- puis implémenté un TfidfVectorizer, \n",
    "\n",
    "3- ensuite, initialisé un PassiveAggressiveClassifier \n",
    "\n",
    "4- et enfin adapté notre modèle.\n",
    "\n",
    "et pour terminer, nous avons fini par obtenir une précision de 92,82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
